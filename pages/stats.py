import dash
from dash import html, dcc
from dash import dash_table
from dash import Input, Output, callback, no_update, State
from mylibrary import *
from myconfig import *
import yaml
import os
import time
import gc
import json
import pandas as pd
import pytz

# Configuration cache for stats page with size limit
_stats_config_cache = {}
_stats_config_cache_timestamp = 0
_stats_config_cache_ttl = 300  # 5 seconds cache TTL
_stats_config_cache_max_size = 10  # Limit cache size



def load_config():
    """Load configuration from YAML file with caching"""
    global _stats_config_cache, _stats_config_cache_timestamp
    
    current_time = time.time()
    if (not _stats_config_cache or 
        current_time - _stats_config_cache_timestamp > _stats_config_cache_ttl):
        
        config_path = os.path.join(os.path.dirname(__file__), '..', 'config.yaml')
        try:
            with open(config_path, 'r', encoding='utf-8') as f:
                _stats_config_cache = yaml.safe_load(f) or {}
            _stats_config_cache_timestamp = current_time
            
            # Limit cache size
            if len(_stats_config_cache) > _stats_config_cache_max_size:
                # Keep only the most recent entries
                keys = list(_stats_config_cache.keys())[:_stats_config_cache_max_size]
                _stats_config_cache = {k: _stats_config_cache[k] for k in keys}
        except (FileNotFoundError, Exception):
            _stats_config_cache = {}
            _stats_config_cache_timestamp = current_time
    
    return _stats_config_cache

def load_core_config():
    """Load core configuration from cached config"""
    config = load_config()
    return config.get('core', {})

# Cache for CI metadata loaded from data/ci_list.json
_ci_meta_cache = None
_ci_meta_cache_mtime = 0

def load_ci_metadata_map():
    """Load CI -> {name, organization} map from data/ci_list.json with basic caching."""
    global _ci_meta_cache, _ci_meta_cache_mtime
    try:
        ci_list_path = os.path.join(os.path.dirname(__file__), '..', 'data', 'ci_list.json')
        if not os.path.exists(ci_list_path):
            return {}
        mtime = os.path.getmtime(ci_list_path)
        if _ci_meta_cache is not None and _ci_meta_cache_mtime == mtime:
            return _ci_meta_cache
        with open(ci_list_path, 'r', encoding='utf-8') as f:
            items = json.load(f) or []
        mapping = {str(item.get('ci')): {
            'name': item.get('name') or '',
            'organization': item.get('organization') or '',
            'product': item.get('product') or ''
        } for item in items if isinstance(item, dict) and item.get('ci')}
        _ci_meta_cache = mapping
        _ci_meta_cache_mtime = mtime
        return mapping
    except Exception:
        return _ci_meta_cache or {}

def get_cached_statistics(config_file_name, cis):
    """Get statistics from JSON file (generated by cron.py) or calculate them if file doesn't exist"""
    
    # Try to load statistics from JSON file first
    statistics_file_path = os.path.join(os.path.dirname(__file__), '..', 'data', 'statistics.json')
    
    try:
        if os.path.exists(statistics_file_path):
            with open(statistics_file_path, 'r', encoding='utf-8') as f:
                file_stats = json.load(f)
            
            # Check if the file has valid statistics
            if file_stats and 'calculated_at' in file_stats:
                file_age = time.time() - file_stats['calculated_at']
                print(f"Using statistics from file (age: {file_age:.1f}s)")
                
                # Convert timestamp strings back to datetime objects for display
                if file_stats.get('latest_timestamp'):
                    file_stats['latest_timestamp'] = pd.to_datetime(file_stats['latest_timestamp'])
                if file_stats.get('earliest_timestamp'):
                    file_stats['earliest_timestamp'] = pd.to_datetime(file_stats['earliest_timestamp'])
                
                # Convert product_counts and organization_counts back to pandas Series
                if file_stats.get('product_counts'):
                    file_stats['product_counts'] = pd.Series(file_stats['product_counts'])
                if file_stats.get('organization_counts'):
                    file_stats['organization_counts'] = pd.Series(file_stats['organization_counts'])
                
                # Ensure overall_availability_percentage_total exists (fallback to overall_availability_percentage)
                if 'overall_availability_percentage_total' not in file_stats:
                    file_stats['overall_availability_percentage_total'] = file_stats.get('overall_availability_percentage', 0)
                
                # Recalculate data age dynamically based on current time
                if file_stats.get('latest_timestamp'):
                    current_time = pd.Timestamp.now(tz=pytz.timezone('Europe/Berlin'))
                    data_age_hours = (current_time - file_stats['latest_timestamp']).total_seconds() / 3600
                    file_stats['data_age_formatted'] = format_duration(data_age_hours)
                
                return file_stats
    except Exception as e:
        print(f"Error loading statistics from file: {e}")
    
    # Fallback: calculate statistics if file doesn't exist or is invalid
    print("Statistics file not available, calculating new statistics")
    new_stats = calculate_overall_statistics(config_file_name, cis)
    
    return new_stats



def format_duration(hours):
    """Format duration in a human-readable way"""
    if hours < 1:
        minutes = int(hours * 60)
        return f"{minutes} Minuten"
    elif hours < 24:
        return f"{hours:.1f} Stunden"
    else:
        days = hours / 24
        return f"{days:.1f} Tage"

def truncate_organization(org_name, max_length=40):
    """Truncate organization name if too long"""
    if not org_name:
        return ""
    if len(org_name) <= max_length:
        return org_name
    return org_name[:max_length-3] + "..."

def calculate_overall_statistics(config_file_name, cis):
    """
    Calculate overall statistics for all Configuration Items including:
    - Total counts and current availability
    - Overall availability percentage
    - Recording time range
    - Product distribution
    - Organization distribution
    """
    if cis.empty:
        return {}
    
    # Basic counts
    total_cis = len(cis)
    currently_available = cis['current_availability'].sum()
    currently_unavailable = total_cis - currently_available
    overall_availability_percentage = (currently_available / total_cis) * 100 if total_cis > 0 else 0
    
    # Product distribution
    product_counts = cis['product'].value_counts()
    total_products = len(product_counts)
    
    # Organization distribution
    organization_counts = cis['organization'].value_counts()
    total_organizations = len(organization_counts)
    
    # Current status distribution
    status_counts = cis['current_availability'].value_counts()
    available_count = status_counts.get(1, 0)
    unavailable_count = status_counts.get(0, 0)
    
    # Recent changes (availability_difference != 0)
    recent_changes = cis[cis['availability_difference'] != 0]
    changes_count = len(recent_changes)
    
    # Get overall recording time range (from the most recent timestamp)
    latest_timestamp = None
    earliest_timestamp = None
    data_age_formatted = "Unbekannt"
    total_recording_minutes = 0
    
    # Try to get timestamps from availability data (where the real time series data is stored)
    try:
        import h5py
        if os.path.exists(config_file_name):
            with h5py.File(config_file_name, 'r', swmr=True) as f:
                if 'availability' in f:
                    availability_group = f['availability']
                    all_timestamps = []
                    
                    # Collect all timestamps from all CIs
                    for ci_name in availability_group.keys():
                        ci_group = availability_group[ci_name]
                        for timestamp_str in ci_group.keys():
                            try:
                                timestamp = pd.to_datetime(float(timestamp_str), unit='s').tz_localize('UTC').tz_convert('Europe/Berlin')
                                all_timestamps.append(timestamp)
                            except:
                                continue
                    
                    print(f"Collected {len(all_timestamps)} timestamps from {len(availability_group.keys())} CIs")
                    
                    if all_timestamps:
                        earliest_timestamp = min(all_timestamps)
                        latest_timestamp = max(all_timestamps)
                        
                        # Get current time in Europe/Berlin
                        current_time = pd.Timestamp.now(tz=pytz.timezone('Europe/Berlin'))
                        data_age_hours = (current_time - latest_timestamp).total_seconds() / 3600
                        data_age_formatted = format_duration(data_age_hours)
                        
                        # Calculate total recording time from the overall time range
                        total_recording_minutes = (latest_timestamp - earliest_timestamp).total_seconds() / 60
                        print(f"Total recording time from availability data: {earliest_timestamp} to {latest_timestamp} = {total_recording_minutes:.1f} minutes ({total_recording_minutes/60/24:.1f} days)")
                        # Also log to stderr for debugging
                        import sys
                        print(f"DEBUG: Total recording time: {total_recording_minutes:.1f} minutes", file=sys.stderr)
                    else:
                        print("No timestamps found in availability data")
    except Exception as e:
        print(f"Error reading availability timestamps: {e}")
    
    # Fallback: Try to get timestamps from different possible columns in general data
    if total_recording_minutes == 0:
        timestamp_columns = ['time', 'timestamp', 'created_at', 'updated_at']
        for col in timestamp_columns:
            if col in cis.columns and not cis[col].isna().all():
                try:
                    latest_timestamp = pd.to_datetime(cis[col].max())
                    earliest_timestamp = pd.to_datetime(cis[col].min())
                    
                    # Ensure both timestamps have timezone info and are in Europe/Berlin
                    if latest_timestamp.tz is None:
                        latest_timestamp = latest_timestamp.tz_localize('Europe/Berlin')
                    elif latest_timestamp.tz != pytz.timezone('Europe/Berlin'):
                        latest_timestamp = latest_timestamp.tz_convert('Europe/Berlin')
                        
                    if earliest_timestamp.tz is None:
                        earliest_timestamp = earliest_timestamp.tz_localize('Europe/Berlin')
                    elif earliest_timestamp.tz != pytz.timezone('Europe/Berlin'):
                        earliest_timestamp = earliest_timestamp.tz_convert('Europe/Berlin')
                    
                    # Get current time in Europe/Berlin
                    current_time = pd.Timestamp.now(tz=pytz.timezone('Europe/Berlin'))
                    data_age_hours = (current_time - latest_timestamp).total_seconds() / 3600
                    data_age_formatted = format_duration(data_age_hours)
                    
                    # Calculate total recording time from the overall time range
                    total_recording_minutes = (latest_timestamp - earliest_timestamp).total_seconds() / 60
                    print(f"Total recording time from general data: {earliest_timestamp} to {latest_timestamp} = {total_recording_minutes:.1f} minutes")
                    break
                except Exception as e:
                    print(f"Error processing timestamp column {col}: {e}")
                    continue
    
    # If no timestamp columns found or all timestamps are the same, try to get from data file metadata
    if total_recording_minutes == 0:
        try:
            # Try to get file modification time as fallback
            import os
            config_file_name = os.path.join(os.path.dirname(__file__), '..', 'data', 'data.hdf5')
            if os.path.exists(config_file_name):
                file_mtime = os.path.getmtime(config_file_name)
                current_time = pd.Timestamp.now(tz=pytz.timezone('Europe/Berlin'))
                file_time = pd.Timestamp.fromtimestamp(file_mtime, tz=pytz.timezone('Europe/Berlin'))
                
                # Calculate duration from file creation to now (more realistic)
                total_recording_minutes = (current_time - file_time).total_seconds() / 60
                latest_timestamp = current_time
                earliest_timestamp = file_time
                data_age_hours = 0  # Current data
                data_age_formatted = "Aktuell"
                print(f"Using file-based calculation: {total_recording_minutes:.1f} minutes ({total_recording_minutes/60/24:.1f} days)")
        except Exception as e:
            print(f"Error in fallback calculation: {e}")
    
    return {
        'total_cis': total_cis,
        'currently_available': currently_available,
        'currently_unavailable': currently_unavailable,
        'overall_availability_percentage': overall_availability_percentage,
        'overall_availability_percentage_total': overall_availability_percentage,  # Same as current availability for now
        'total_products': total_products,
        'total_organizations': total_organizations,
        'available_count': available_count,
        'unavailable_count': unavailable_count,
        'changes_count': changes_count,
        'latest_timestamp': latest_timestamp,
        'earliest_timestamp': earliest_timestamp,
        'data_age_formatted': data_age_formatted,
        'product_counts': product_counts,
        'organization_counts': organization_counts,
        'total_recording_minutes': total_recording_minutes
    }

dash.register_page(__name__, path='/stats')

def create_overall_statistics_display(stats):
    """Create the overall statistics display section"""
    children = [
        html.H3('üìä Gesamtstatistik aller Configuration Items'),
        
        # Main overview
        html.Div(className='stats-overview', children=[
            html.Div(className='stat-card', children=[
                html.H4('üéØ √úbersicht'),
                html.Div(className='stat-grid', children=[
                    html.Div(className='stat-item', children=[
                        html.Strong('Gesamtanzahl CIs: '),
                        html.Span(f'{stats["total_cis"]:,}')
                    ]),
                    html.Div(className='stat-item', children=[
                        html.Strong('Aktuell verf√ºgbar: '),
                        html.Span(f'{stats["currently_available"]:,}')
                    ]),
                    html.Div(className='stat-item', children=[
                        html.Strong('Aktuell nicht verf√ºgbar: '),
                        html.Span(f'{stats["currently_unavailable"]:,}')
                    ]),
                    html.Div(className='stat-item', children=[
                        html.Strong('Gesamtverf√ºgbarkeit (aktuelle Daten): ', title='Zeitgewichtete Verf√ºgbarkeit √ºber alle CIs im √ºberwachten Zeitraum'),
                        html.Span(
                            f"{(stats.get('overall_availability_percentage_rollup') if stats.get('overall_availability_percentage_rollup') is not None else stats.get('overall_availability_percentage', 0)):.2f}%",
                            title='Zeitgewichtete Verf√ºgbarkeit √ºber alle CIs im √ºberwachten Zeitraum'
                        )
                    ]),
                    html.Div(className='stat-item', children=[
                        html.Strong('Gesamtdauer Aufzeichnung: '),
                        html.Span(format_duration(stats["total_recording_minutes"] / 60) if stats.get("total_recording_minutes", 0) > 0 else 'Unbekannt')
                    ]),
                    html.Div(className='stat-item', children=[
                        html.Strong('Kumulative Uptime (√ºber alle CIs): ', title='Summe der Betriebszeiten aller CIs im Zeitraum'),
                        html.Span(
                            format_duration((stats.get('overall_uptime_minutes') or 0) / 60),
                            title='Summe der Betriebszeiten aller CIs im Zeitraum'
                        )
                    ]),
                    html.Div(className='stat-item', children=[
                        html.Strong('√ò Uptime pro CI im Zeitraum: ', title='Durchschnittliche Betriebszeit je CI im Zeitraum'),
                        html.Span(
                            format_duration(
                                (
                                    ((stats.get('overall_uptime_minutes') or 0) / max(1, int(stats.get('total_cis', 0))))
                                ) / 60
                            ),
                            title='Durchschnittliche Betriebszeit je CI im Zeitraum'
                        )
                    ]),
                    html.Div(className='stat-item', children=[
                        html.Strong('Gesamte Downtime: '),
                        html.Span(format_duration((stats.get('overall_downtime_minutes') or 0) / 60))
                    ]),
                    html.Div(className='stat-item', children=[
                        html.Strong('Incidents (gesamt): ', title='Anzahl Ausf√§lle (√úberg√§nge von verf√ºgbar zu nicht verf√ºgbar)'),
                        html.Span(f"{int(stats.get('total_incidents', 0))}", title='Anzahl Ausf√§lle (√úberg√§nge von verf√ºgbar zu nicht verf√ºgbar)')
                    ]),
                    html.Div(className='stat-item', children=[
                        html.Strong('MTTR (√ò, Minuten): ', title='Mean Time To Repair ‚Äì durchschnittliche Dauer eines Ausfalls bis zur Wiederherstellung'),
                        html.Span(f"{(stats.get('mttr_minutes_mean') or 0):.1f}", title='Mean Time To Repair ‚Äì durchschnittliche Dauer eines Ausfalls bis zur Wiederherstellung')
                    ]),
                    html.Div(className='stat-item', children=[
                        html.Strong('MTBF (√ò, Minuten): ', title='Mean Time Between Failures ‚Äì mittlere Zeit zwischen zwei Ausf√§llen'),
                        html.Span(f"{(stats.get('mtbf_minutes_mean') or 0):.1f}", title='Mean Time Between Failures ‚Äì mittlere Zeit zwischen zwei Ausf√§llen')
                    ])
                ])
            ]),
            
            html.Div(className='stat-card', children=[
                html.H4('üìÖ Datenstatus'),
                html.Div(className='stat-grid', children=[
                    html.Div(className='stat-item', children=[
                        html.Strong('Letzte Aktualisierung: '),
                        html.Span(stats["latest_timestamp"].strftime('%d.%m.%Y %H:%M:%S Uhr') if stats["latest_timestamp"] else 'Unbekannt')
                    ]),
                    html.Div(className='stat-item', children=[
                        html.Strong('N√§chste Aktualisierung: '),
                        html.Span((stats["latest_timestamp"] + pd.Timedelta(hours=1)).strftime('%d.%m.%Y %H:%M:%S Uhr') if stats["latest_timestamp"] else 'Unbekannt')
                    ]),
                    html.Div(className='stat-item', children=[
                        html.Strong('Datenalter: '),
                        html.Span(stats["data_age_formatted"])
                    ]),
                    html.Div(className='stat-item', children=[
                        html.Strong('K√ºrzliche √Ñnderungen: '),
                        html.Span(f'{stats["changes_count"]:,}')
                    ]),
                    html.Div(className='stat-item', children=[
                        html.Strong('Datenbankgr√∂√üe: '),
                        html.Span(f'{stats.get("database_size_mb", 0):.1f} MB')
                    ])
                ])
            ]),
            

        ])
    ]
    
    # Add comprehensive availability statistics
    if stats.get('total_recording_minutes', 0) > 0:
        children.append(
            html.Div(className='comprehensive-availability', children=[
                html.H4('‚è±Ô∏è Gesamtverf√ºgbarkeit √ºber alle CIs'),
                html.Div(className='stat-grid', children=[
                    html.Div(className='stat-item', children=[
                        html.Strong('Gesamtverf√ºgbarkeit (Zeitbasis): '),
                        html.Span(f'{stats["overall_availability_percentage_total"]:.2f}%')
                    ]),
                    html.Div(className='stat-item', children=[
                        html.Strong('Gesamtaufzeichnungszeit: '),
                        html.Span(format_duration(stats["total_recording_minutes"] / 60))
                    ])
                ])
            ])
        )
    

    

    
    return html.Div(className='overall-statistics box', children=children)

def serve_layout():
    # Load core configurations (now cached)
    core_config = load_core_config()
    
    # Get file_name from YAML as primary source, fallback to myconfig.py
    config_file_name = core_config.get('file_name') or file_name
    config_url = core_config.get('url')
    
    # Check if data file exists and initialize if needed
    if not os.path.exists(config_file_name):
        try:
            # Create data directory if it doesn't exist
            os.makedirs(os.path.dirname(config_file_name), exist_ok=True)
            # Initialize empty data file
            initialize_data_file(config_file_name)
            print(f"Initialized data file: {config_file_name}")
        except Exception as e:
            print(f"Error initializing data file: {e}")
    
    # Try to get data
    try:
        cis = get_data_of_all_cis(config_file_name)
    except Exception as e:
        print(f"Error reading data: {e}")
        cis = pd.DataFrame()  # Empty DataFrame
    
    # Check if DataFrame is empty
    if cis.empty:
        # Try to load data from API if URL is available
        if config_url:
            try:
                print(f"Loading data from API: {config_url}")
                update_file(config_file_name, config_url)
                # Try to read data again
                cis = get_data_of_all_cis(config_file_name)
                print(f"Loaded {len(cis)} records from API")
            except Exception as e:
                print(f"Error loading data from API: {e}")
        
        # If still empty, show message
        if cis.empty:
            layout = html.Div([
                html.P('Keine Daten verf√ºgbar. Versuche Daten von der API zu laden...'),
                html.P('Falls das Problem weiterhin besteht, √ºberpr√ºfen Sie die API-Verbindung.'),
                html.P(f'API URL: {config_url or "Nicht konfiguriert"}'),
                html.P(f'Daten-Datei: {config_file_name}')
            ])
            return layout
    
    # Check if 'product' column exists
    if 'product' not in cis.columns:
        layout = html.Div([
            html.P('Daten sind verf√ºgbar, aber die Spalte "product" fehlt. M√∂glicherweise ist die Datenstruktur fehlerhaft.'),
            html.P('Verf√ºgbare Spalten: ' + ', '.join(cis.columns.tolist())),
            html.P(f'Anzahl Datens√§tze: {len(cis)}')
        ])
        return layout
    
    # Get statistics from cache or calculate them
    overall_stats = get_cached_statistics(config_file_name, cis)
    
    # Force garbage collection periodically to prevent memory buildup
    if int(time.time()) % 300 == 0:  # Every 5 minutes
        gc.collect()
    
    layout = html.Div([
        html.P('Hier finden Sie eine umfassende Gesamtstatistik aller Configuration Items. Neue Daten werden st√ºndlich von cron.py berechnet und gecacht. Laden Sie die Seite neu, um die Ansicht zu aktualisieren.'),
        
        # Cache information
        html.Div(className='cache-info', children=[
            html.P(f'üìä Statistiken werden st√ºndlich von cron.py berechnet und gecacht'),
            html.P(f'üîÑ N√§chste Aktualisierung: St√ºndlich')
        ]),
        
        # Overall statistics section
        create_overall_statistics_display(overall_stats),
        
        # Location component for navigation
        dcc.Location(id='stats-location', refresh=False),
        
        # Top-Listen (sortable DataTable)
        html.Div(className='overall-statistics box', children=[
            html.Div(className='stat-card', children=[
                html.H4('üö® Top instabile CIs (Incidents)'),
                (lambda rows: dash_table.DataTable(
                    id='unstable-cis-table',
                    data=rows,
                    row_selectable=False,
                    row_deletable=False,
                    columns=[
                        {"name": "Organisation", "id": "organization"},
                        {"name": "Name", "id": "name"},
                        {"name": "Produkt", "id": "product"},
                        {"name": "Incidents", "id": "incidents", "type": "numeric"},
                        {"name": "Downtime (Minuten)", "id": "downtime_minutes", "type": "numeric", "format": {"specifier": ".0f"}},
                        {"name": "Verf√ºgbarkeit (%)", "id": "availability_percentage", "type": "numeric", "format": {"specifier": ".2f"}},
                    ],
                    sort_action='native',
                    sort_mode='multi',
                    style_table={'overflowX': 'auto', 'minWidth': '100%', 'backgroundColor': 'var(--bg-color)', 'color': 'var(--text-color)'},
                    style_cell={'padding': '8px', 'fontSize': '0.95rem', 'backgroundColor': 'var(--bg-color)', 'color': 'var(--text-color)', 'border': '1px solid var(--border-color)'},
                    style_cell_conditional=[
                        {"if": {"column_id": "organization"}, "textAlign": "left", "maxWidth": "120px", "minWidth": "100px", "overflow": "hidden", "textOverflow": "ellipsis"},
                        {"if": {"column_id": "name"}, "textAlign": "left", "maxWidth": "150px", "minWidth": "120px", "overflow": "hidden", "textOverflow": "ellipsis"},
                        {"if": {"column_id": "product"}, "textAlign": "left", "maxWidth": "120px", "minWidth": "100px", "overflow": "hidden", "textOverflow": "ellipsis"},
                        {"if": {"column_id": "incidents"}, "textAlign": "right", "maxWidth": "80px", "minWidth": "60px", 'fontVariantNumeric': 'tabular-nums'},
                        {"if": {"column_id": "downtime_minutes"}, "textAlign": "right", "maxWidth": "100px", "minWidth": "80px", 'fontVariantNumeric': 'tabular-nums'},
                        {"if": {"column_id": "availability_percentage"}, "textAlign": "right", "maxWidth": "100px", "minWidth": "80px", 'fontVariantNumeric': 'tabular-nums'},
                    ],
                    style_header={'backgroundColor': 'var(--card-bg-color)', 'color': '#ffffff', 'fontWeight': 'bold'},
                    style_data_conditional=[
                        {
                            'if': {'state': 'active'},
                            'backgroundColor': 'var(--primary-color)',
                            'color': 'white',
                        },
                        {
                            'if': {'state': 'selected'},
                            'backgroundColor': 'var(--primary-color-light)',
                            'color': 'white',
                        }
                    ],
                    css=[
                        {
                            'selector': '.dash-table-container .dash-spreadsheet-container .dash-spreadsheet-inner table',
                            'rule': 'cursor: pointer;'
                        },
                        {
                            'selector': '.dash-table-container',
                            'rule': 'overflow-x: auto; -webkit-overflow-scrolling: touch;'
                        },
                        {
                            'selector': '.dash-table-container .dash-spreadsheet-container',
                            'rule': 'min-width: 600px;'
                        }
                    ],
                    tooltip_data=[
                        {
                            'organization': {'value': r.get('ci','‚Äî'), 'type': 'text'},
                            'name': {'value': r.get('ci','‚Äî'), 'type': 'text'},
                            'product': {'value': r.get('ci','‚Äî'), 'type': 'text'}
                        } for r in rows
                    ],
                    tooltip_duration=None

                ))([
                    {
                        'ci': entry['ci'],
                        'name': (
                            overall_stats.get('per_ci_metrics', {}).get(entry['ci'], {}).get('name')
                            or load_ci_metadata_map().get(entry['ci'], {}).get('name')
                            or ''
                        ),
                        'organization': truncate_organization(
                            overall_stats.get('per_ci_metrics', {}).get(entry['ci'], {}).get('organization')
                            or load_ci_metadata_map().get(entry['ci'], {}).get('organization')
                            or ''
                        ),
                        'product': (
                            overall_stats.get('per_ci_metrics', {}).get(entry['ci'], {}).get('product')
                            or load_ci_metadata_map().get(entry['ci'], {}).get('product')
                            or ''
                        ),
                        'incidents': int(entry['incidents']),
                        'downtime_minutes': round(float(overall_stats.get('per_ci_metrics', {}).get(entry['ci'], {}).get('downtime_minutes', 0.0))),
                        'availability_percentage': round(float(overall_stats.get('per_ci_metrics', {}).get(entry['ci'], {}).get('availability_percentage', 0.0)), 2),
                    }
                    for entry in sorted(
                        overall_stats.get('top_unstable_cis_by_incidents', []),
                        key=lambda entry: (
                            float(overall_stats.get('per_ci_metrics', {}).get(entry['ci'], {}).get('availability_percentage', 0.0)),
                            -int(entry['incidents'])
                        )
                    )
                ])
            ])
        ])
    ])
    
    return layout

layout = serve_layout

# Add a clientside callback for navigation
from dash import clientside_callback

clientside_callback(
    """
    function(active_cell, table_data) {
        if (active_cell && table_data) {
            const rowIndex = active_cell.row;
            if (rowIndex !== null && rowIndex < table_data.length) {
                const ci = table_data[rowIndex].ci;
                if (ci) {
                    window.location.href = '/plot?ci=' + ci;
                }
            }
        }
        return window.dash_clientside.no_update;
    }
    """,
    Output('stats-location', 'href'),
    [Input('unstable-cis-table', 'active_cell')],
    [State('unstable-cis-table', 'data')],
    prevent_initial_call=True
)
